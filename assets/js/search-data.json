{
  
    
        "post0": {
            "title": "Distinguish Your Own Digits (DYOD)",
            "content": "You are going to write a classifier that distinguishes between the number 3 and number 8. . %load_ext autoreload %autoreload 2 . %matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd . From the command line run pip install mnist. This is a library that will help you bring down the mnist dataset. If you run this from a notebook, you need to put !pip install mnist in a cell by itself. . !pip install mnist . Requirement already satisfied: mnist in c: users deepthi anaconda3 lib site-packages (0.2.2) Requirement already satisfied: numpy in c: users deepthi anaconda3 lib site-packages (from mnist) (1.16.4) . Preparing the Data . import mnist . train_images = mnist.train_images() train_labels = mnist.train_labels() . train_images.shape, train_labels.shape . ((60000, 28, 28), (60000,)) . test_images = mnist.test_images() test_labels = mnist.test_labels() . test_images.shape, test_labels.shape . ((10000, 28, 28), (10000,)) . image_index = 7776 # You may select anything up to 60,000 print(train_labels[image_index]) plt.imshow(train_images[image_index], cmap=&#39;Greys&#39;) . 2 . &lt;matplotlib.image.AxesImage at 0x1fa2ebbdd30&gt; . Filter data to get 3 and 8 out . train_filter = np.where((train_labels == 3 ) | (train_labels == 8)) test_filter = np.where((test_labels == 3) | (test_labels == 8)) X_train, y_train = train_images[train_filter], train_labels[train_filter] X_test, y_test = test_images[test_filter], test_labels[test_filter] . We normalize the pizel values in the 0 to 1 range . X_train = X_train/255. X_test = X_test/255. . And setup the labels as 1 (when the digit is 3) and 0 (when the digit is 8) . y_train = 1*(y_train==3) y_test = 1*(y_test==3) . X_train.shape, X_test.shape . ((11982, 28, 28), (1984, 28, 28)) . We reshape the data to flatten the image pixels into a set of features or co-variates: . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . #Impoting functions from &#39;Kudzu&#39; from kudzu.model import Model from kudzu.train import Learner from kudzu.optim import GD from kudzu.data import Data, Sampler,Dataloader from kudzu.callbacks import AccCallback from kudzu.callbacks import ClfCallback from kudzu.loss import MSE from kudzu.layer import Sigmoid,Relu from kudzu.layer import Affine . Let us create a Config class, to store important parameters. . This class essentially plays the role of a dictionary. . class Config: pass config = Config() config.lr = 0.001 config.num_epochs = 250 config.bs = 50 . Running Models with the Training data . Details about the network layers: . A first affine layer has 784 inputs and does 100 affine transforms. These are followed by a Relu | A second affine layer has 100 inputs from the 100 activations of the past layer, and does 100 affine transforms. These are followed by a Relu | A third affine layer has 100 activations and does 2 affine transformations to create an embedding for visualization. There is no non-linearity here. | A final &quot;logistic regression&quot; which has an affine transform from 2 inputs to 1 output, which is squeezed through a sigmoid. | . data = Data(X_train, y_train.reshape(-1,1)) sampler = Sampler(data, config.bs, shuffle=True) dl = Dataloader(data, sampler) opt = GD(config.lr) loss = MSE() . training_data_x = X_train testing_data_x = X_test training_data_y = y_train.reshape(-1,1) testing_data_y = y_test.reshape(-1,1) . layers = [Affine(&quot;first&quot;, 784, 100), Relu(&quot;first&quot;), Affine(&quot;second&quot;, 100, 100), Relu(&quot;second&quot;), Affine(&quot;third&quot;, 100, 2), Affine(&quot;last&quot;, 2, 1), Sigmoid(&quot;last&quot;)] model_nn = Model(layers) model_lr = Model([Affine(&quot;logits&quot;, 784, 1), Sigmoid(&quot;sigmoid&quot;)]) . xavier xavier xavier xavier xavier . nn_learner = Learner(loss, model_nn, opt, config.num_epochs) acc_nn = ClfCallback(nn_learner, config.bs, training_data_x , testing_data_x, training_data_y, testing_data_y) nn_learner.set_callbacks([acc_nn]) . lr_learner = Learner(loss, model_lr, opt, config.num_epochs) acc_lr = ClfCallback(lr_learner, config.bs, training_data_x , testing_data_x, training_data_y, testing_data_y) lr_learner.set_callbacks([acc_lr]) . nn_learner.train_loop(dl) . Epoch 0, Loss 0.0197 Training Accuracy: 0.9779, Testing Accuracy: 0.9753 . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-25-52d433503d1c&gt; in &lt;module&gt; -&gt; 1 nn_learner.train_loop(dl) ~ programs project kudzu train.py in train_loop(self, dl) 45 # calculate gradient 46 intermed = self.loss.backward(predicted, targets) &gt; 47 self.model.backward(intermed) 48 49 # make step ~ programs project kudzu model.py in backward(self, grad) 14 for layer in reversed(self.layers): 15 #print(layer.name, &#34;incoming&#34;, grad) &gt; 16 grad = layer.backward(grad) 17 return grad 18 ~ programs project kudzu layer.py in backward(self, grad) 42 self.grads[&#39;b&#39;] = np.sum(grad, axis=0) 43 # return (n, 1) @ (1 , m) = (n, m) &gt; 44 return grad@self.params[&#39;w&#39;].T 45 46 KeyboardInterrupt: . lr_learner.train_loop(dl) . Epoch 0, Loss 0.0367 Training Accuracy: 0.9600, Testing Accuracy: 0.9657 Epoch 10, Loss 0.0364 Training Accuracy: 0.9603, Testing Accuracy: 0.9657 Epoch 20, Loss 0.0361 Training Accuracy: 0.9605, Testing Accuracy: 0.9662 Epoch 30, Loss 0.0358 Training Accuracy: 0.9606, Testing Accuracy: 0.9667 Epoch 40, Loss 0.0355 Training Accuracy: 0.9606, Testing Accuracy: 0.9667 Epoch 50, Loss 0.0353 Training Accuracy: 0.9610, Testing Accuracy: 0.9662 Epoch 60, Loss 0.035 Training Accuracy: 0.9611, Testing Accuracy: 0.9662 Epoch 70, Loss 0.0348 Training Accuracy: 0.9613, Testing Accuracy: 0.9662 Epoch 80, Loss 0.0346 Training Accuracy: 0.9614, Testing Accuracy: 0.9662 Epoch 90, Loss 0.0344 Training Accuracy: 0.9615, Testing Accuracy: 0.9657 Epoch 100, Loss 0.0342 Training Accuracy: 0.9616, Testing Accuracy: 0.9662 Epoch 110, Loss 0.034 Training Accuracy: 0.9620, Testing Accuracy: 0.9662 Epoch 120, Loss 0.0338 Training Accuracy: 0.9623, Testing Accuracy: 0.9662 Epoch 130, Loss 0.0336 Training Accuracy: 0.9624, Testing Accuracy: 0.9662 Epoch 140, Loss 0.0334 Training Accuracy: 0.9626, Testing Accuracy: 0.9667 Epoch 150, Loss 0.0333 Training Accuracy: 0.9626, Testing Accuracy: 0.9667 Epoch 160, Loss 0.0331 Training Accuracy: 0.9627, Testing Accuracy: 0.9667 Epoch 170, Loss 0.0329 Training Accuracy: 0.9627, Testing Accuracy: 0.9667 Epoch 180, Loss 0.0328 Training Accuracy: 0.9629, Testing Accuracy: 0.9672 Epoch 190, Loss 0.0326 Training Accuracy: 0.9630, Testing Accuracy: 0.9672 Epoch 200, Loss 0.0325 Training Accuracy: 0.9632, Testing Accuracy: 0.9672 Epoch 210, Loss 0.0323 Training Accuracy: 0.9634, Testing Accuracy: 0.9677 Epoch 220, Loss 0.0322 Training Accuracy: 0.9634, Testing Accuracy: 0.9677 Epoch 230, Loss 0.0321 Training Accuracy: 0.9638, Testing Accuracy: 0.9677 Epoch 240, Loss 0.032 Training Accuracy: 0.9640, Testing Accuracy: 0.9677 . 0.053878465819866675 . #comparing the results of NN and LR plt.figure(figsize=(15,10)) # Neural Network plots plt.plot(acc_nn.accuracies, &#39;r-&#39;, label = &quot;Training Accuracies - NN&quot;) plt.plot(acc_nn.test_accuracies, &#39;g-&#39;, label = &quot;Testing Accuracies - NN&quot;) # Logistic Regression plots plt.plot(acc_lr.accuracies, &#39;k-&#39;, label = &quot;Training Accuracies - LR&quot;) plt.plot(acc_lr.test_accuracies, &#39;b-&#39;, label = &quot;Testing Accuracies - LR&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1fa355cee10&gt; . Plotting the outputs of this layer of the NN. . new_model = Model(layers[:-2]) testing_plot = new_model(testing_data_x) . # Plotting the scatter plot of points and color coding by class plt.figure(figsize=(8,7)) plt.scatter(testing_plot[:,0], testing_plot[:,1], alpha = 0.1, c = y_test.ravel()); plt.title(&#39;Outputs&#39;) . Text(0.5, 1.0, &#39;Outputs&#39;) . Probability contours . model_prob = Model(layers[-2:]) . #creating the x and y ranges according to the above generated plot. x_range = np.linspace(-4, 1, 100) y_range = np.linspace(-6, 6, 100) x_grid, y_grid = np.meshgrid(x_range, y_range) # x_grid and y_grig are of size 100 X 100 # converting x_grid and y_grid to continuous arrays x_gridflat = np.ravel(x_grid) y_gridflat = np.ravel(y_grid) # The last layer of the current model takes two columns as input. Hence transpose of np.vstack() is required. X = np.vstack((x_gridflat, y_gridflat)).T prob_contour = model_prob(X).reshape(100,100) . plt.figure(figsize=(10,9)) plt.scatter(testing_plot[:,0], testing_plot[:,1], alpha = 0.1, c = y_test.ravel()) contours = plt.contour(x_grid,y_grid,prob_contour) plt.title(&#39;Probability Contours&#39;) plt.clabel(contours, inline = True ); .",
            "url": "https://bhanushashank.github.io/sample-blog/2020/08/11/part2.html",
            "relUrl": "/2020/08/11/part2.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": " Dashboard for covid-19: Auto-updated",
            "content": "Welcome! This version of the dashboard updates itself everyday with the latest information. . #collapse from datetime import datetime import pandas as pd import numpy as np # For making web-requests to the website import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl %matplotlib inline from IPython.core.display import display,HTML latest_df = pd.read_csv(&quot;https://api.covid19india.org/csv/latest/state_wise_daily.csv&quot;) latest_df.head() df_1 = latest_df[(latest_df.Status == &quot;Confirmed&quot;)] df_1 = df_1.drop(columns = [&quot;Status&quot;]) df_2 = latest_df[(latest_df.Status == &quot;Deceased&quot;)] df_2 = df_2.drop(columns = [&quot;Status&quot;]) df_1[&quot;Date&quot;] = df_1[&quot;Date&quot;].astype(&#39;datetime64[ns]&#39;) update = latest_df.iloc[-1,0] cases = df_1.TT.sum() new = df_1.iloc[-1,1] deaths = df_2.TT.sum() df_new = df_2.iloc[-1,1] overview = &#39;&#39;&#39; &lt;!-- ####### HTML!! #########--&gt; &lt;h1 style=&quot;color: #5e9ca0; text-align: center;&quot;&gt;India&lt;/h1&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Last update: &lt;strong&gt;{update}&lt;/strong&gt;&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed cases:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{cases} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{new}&lt;/span&gt;)&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed deaths:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{deaths} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{df_new}&lt;/span&gt;)&lt;/p&gt; &#39;&#39;&#39; html = HTML(overview.format(update=update, cases=cases,new=new,deaths=deaths,df_new=df_new)) display(html) . . India . Last update: 10-Aug-20 . Confirmed cases: . 2267061 (+53016) . Confirmed deaths: . 45364 (+887) . #collapse current_time = datetime.now().time() # time object print(&quot;Last Updated: &quot;, current_time) . . Last Updated: 21:30:26.255934 . #collapse # For ten states n = 10 st = [&quot;TT&quot;, &quot;MH&quot;, &quot;TN&quot;, &quot;DL&quot;, &quot;KA&quot;, &quot;UP&quot;, &quot;BR&quot;, &quot;WB&quot;, &quot;TG&quot;, &quot;AP&quot;] state_name = [&quot;India&quot;, &quot;Maharashta&quot;, &quot;Tamil Nadu&quot;, &quot;Delhi&quot;, &quot;Karnataka&quot;, &quot;Uttar Pradesh&quot;, &quot;Bihar&quot;, &quot;West Bengal&quot;, &quot;Telangana&quot;, &quot;Andhra Pradesh&quot;] fig = plt.figure(figsize = (16,30)) gridspec = fig.add_gridspec(n, 3) for i in range(n): ax = fig.add_subplot(gridspec[i, :]) ax.bar(df_1.Date,df_1[st[i]],alpha=0.3,color=&#39;#007acc&#39;) ax.plot(df_1.Date,df_1[st[i]] , marker=&quot;o&quot;, color=&#39;#007acc&#39;) ax.xaxis.set_major_locator(mdates.WeekdayLocator()) ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax.text(0.02, 0.5,state_name[i], transform = ax.transAxes, fontsize=25) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) . .",
            "url": "https://bhanushashank.github.io/sample-blog/2020/08/11/autoupdated.html",
            "relUrl": "/2020/08/11/autoupdated.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Dashboard for Covid-19",
            "content": "#collapse ## Import essential packages below import pandas as pd import numpy as np import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl from IPython.core.display import display,HTML %matplotlib inline dft_cases = pd.read_csv(&#39;SnapshotCases-28-July.csv&#39;) dft_deaths = pd.read_csv(&#39;SnapshotDeaths-28-July.csv&#39;) dft_cases[&quot;dt_today&quot;] = dft_cases[&quot;28-Jul-20&quot;] dft_cases[&quot;dt_yday&quot;] = dft_cases[&quot;27-Jul-20&quot;] dft_deaths[&quot;dt_today&quot;] = dft_deaths[&quot;28-Jul-20&quot;] dft_deaths[&quot;dt_yday&quot;] = dft_deaths[&quot;27-Jul-20&quot;] # Get the latest count of the total number of cases for each state across India, and also one from a day before dfc_cases = dft_cases.groupby(&#39;states&#39;)[&#39;dt_today&#39;].sum() dfc_deaths = dft_deaths.groupby(&#39;states&#39;)[&#39;dt_today&#39;].sum() dfp_cases = dft_cases.groupby(&#39;states&#39;)[&#39;dt_yday&#39;].sum() dfp_deaths = dft_deaths.groupby(&#39;states&#39;)[&#39;dt_yday&#39;].sum() products = {&#39;states&#39;:dft_cases.states, &#39;Cases&#39;:dfc_cases.values , &#39;Deaths&#39;:dfc_deaths.values , &#39;PCases&#39;:dfp_cases.values, &#39;PDeaths&#39;:dfp_deaths.values } df_table = pd.DataFrame(products, columns= [&#39;states&#39;,&#39;Cases&#39;, &#39;Deaths&#39;,&#39;PCases&#39;,&#39;PDeaths&#39;]) df_table.sort_values(by = [&#39;Cases&#39;,&#39;Deaths&#39;],inplace=True, ascending = [False,False]) df_table=df_table.reset_index() for c in &#39;Cases, Deaths&#39;.split(&#39;, &#39;): df_table[f&#39;{c} (+)&#39;] = (df_table[c] - df_table[f&#39;P{c}&#39;]).clip(0) df_table[&#39;Fatality Rate&#39;] = (100* df_table[&#39;Deaths&#39;]/ df_table[&#39;Cases&#39;]).round(2) summary = {&quot;updated&quot;:&quot;28th July, 2020&quot;, &quot;since&quot;:&quot;27th July, 2020&quot;} for i in df_table.columns: if i not in [&#39;States&#39;, &#39;Fatality Rate&#39;]: summary[i] = df_table[i].sum() update = summary[&#39;updated&#39;] cases = summary[&#39;Cases&#39;] new = summary[&#39;Cases (+)&#39;] deaths = summary[&#39;Deaths&#39;] dnew = summary[&#39;Deaths (+)&#39;] . . India . Last update: 28th July, 2020 . Confirmed cases: . 1514800 (+49001) . Confirmed deaths: . 34121 (+770) . index states Cases Deaths PCases PDeaths Cases (+) Deaths (+) Fatality Rate 18 Maharashtra 391440 14164 383723 13882 7717 282 3.62 28 Tamil Nadu 227688 3659 220716 3571 6972 88 1.61 7 Delhi 132275 3881 131219 3853 1056 28 2.93 1 Andhra Pradesh 110297 1148 102349 1090 7948 58 1.04 14 Karnataka 107001 2064 101465 1962 5536 102 1.93 31 Uttar Pradesh 73951 1497 70493 1456 3458 41 2.02 32 West Bengal 62964 1449 60830 1411 2134 38 2.30 9 Gujarat 57982 2372 56874 2348 1108 24 4.09 29 Telangana 57142 480 55532 471 1610 9 0.84 4 Bihar 43591 269 41111 255 2480 14 0.62 26 Rajasthan 38636 644 37564 633 1072 11 1.67 3 Assam 34846 92 33475 90 1371 2 0.26 10 Haryana 32876 406 32127 397 749 9 1.23 17 Madhya Pradesh 29217 831 28589 821 628 10 2.84 23 Orissa 28107 189 26892 181 1215 8 0.67 15 Kerala 20895 68 19728 64 1167 4 0.33 12 Jammu and Kashmir 18879 333 18390 321 489 12 1.76 25 Punjab 14378 336 13769 318 609 18 2.34 13 Jharkhand 9563 94 8803 90 760 4 0.98 8 Goa 5287 36 5119 36 168 0 0.68 30 Tripura 4287 21 4066 17 221 4 0.49 24 Pondicherry 3013 47 2874 43 139 4 1.56 11 Himachal Pradesh 2330 13 2270 13 60 0 0.56 19 Manipur 2317 0 2286 0 31 0 0.00 22 Nagaland 1460 4 1385 5 75 0 0.27 2 Arunachal Pradesh 1330 3 1239 3 91 0 0.23 5 Chandigarh 934 14 910 14 24 0 1.50 20 Meghalaya 779 5 738 5 41 0 0.64 27 Sikkim 592 1 568 1 24 0 0.17 21 Mizoram 384 0 361 0 23 0 0.00 0 Andaman and Nicobar Islands 359 1 334 1 25 0 0.28 6 Daman and Diu 0 0 0 0 0 0 NaN 16 Lakshadweep 0 0 0 0 0 0 NaN .",
            "url": "https://bhanushashank.github.io/sample-blog/2020/08/10/part1.html",
            "relUrl": "/2020/08/10/part1.html",
            "date": " • Aug 10, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://bhanushashank.github.io/sample-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}